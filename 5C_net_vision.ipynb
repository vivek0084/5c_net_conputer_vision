{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1K1_f0rv4Li"
      },
      "outputs": [],
      "source": [
        
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# CLAHE preprocessing\n",
        "def clahe_preprocess(img):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    return clahe.apply(img)\n",
        "\n",
        "# Function to load images and masks from zip and preprocess\n",
        "def load_images_from_zip(zip_file_path, image_ext=\".tif\"):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_file_list = zip_ref.namelist()\n",
        "        image_files = sorted([f for f in zip_file_list if f.endswith(image_ext) and \"mask\" not in f])\n",
        "        mask_files = sorted([f for f in zip_file_list if f.endswith(image_ext) and \"mask\" in f])\n",
        "\n",
        "        for image_file, mask_file in tqdm(zip(image_files, mask_files), total=len(image_files), desc=\"Loading Images and Masks\"):\n",
        "            # Read the image file from the ZIP\n",
        "            with zip_ref.open(image_file) as img_file:\n",
        "                img_data = img_file.read()\n",
        "                img_array = np.frombuffer(img_data, np.uint8)\n",
        "                img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # Check if the image was decoded successfully\n",
        "                if img is not None:\n",
        "                    preprocessed_img = clahe_preprocess(img)\n",
        "                    images.append(preprocessed_img)\n",
        "                else:\n",
        "                    print(f\"Warning: Could not decode image file {image_file}, skipping.\")\n",
        "\n",
        "            # Read the mask file from the ZIP\n",
        "            with zip_ref.open(mask_file) as mask_file:\n",
        "                mask_data = mask_file.read()\n",
        "                mask_array = np.frombuffer(mask_data, np.uint8)\n",
        "                mask = cv2.imdecode(mask_array, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # Check if the mask was decoded successfully\n",
        "                if mask is not None:\n",
        "                    masks.append(mask)\n",
        "                else:\n",
        "                    print(f\"Warning: Could not decode mask file {mask_file}, skipping.\")\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "# Example usage\n",
        "zip_file_path = \"/content/Data (1).zip\"\n",
        "X_images, Y_masks = load_images_from_zip(zip_file_path)\n",
        "\n",
        "# Data normalization and splitting (80% training, 20% testing)\n",
        "X_images = X_images / 255.0  # Normalization\n",
        "Y_masks = Y_masks / 255.0  # Normalize masks to range [0, 1]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_images, Y_masks, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verifying the split\n",
        "print(f\"Training data: {len(X_train)} images, Testing data: {len(X_test)} images\")\n",
        "[11:27, 01/10/2024] Kausik SRM: import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def unet_pp(input_size=(256, 256, 1)):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # Downsampling path\n",
        "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Upsampling path\n",
        "    up2 = layers.UpSampling2D(size=(4, 4))(pool2)  # Upsample back to 256x256\n",
        "    up2_conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up2)\n",
        "\n",
        "    # Concatenate the upsampled feature map with the corresponding downsampled feature map\n",
        "    merge2 = layers.Concatenate(axis=3)([conv1, up2_conv])\n",
        "\n",
        "    conv_final = layers.Conv2D(1, (1, 1), activation='sigmoid')(merge2)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv_final)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
        "\n",
        "    return model\n",
        "\n",
        "unetpp_model = unet_pp()\n",
        "unetpp_model.summary()\n",
        "[11:39, 01/10/2024] Kausik SRM: import zipfile\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Data Preprocessing and Loading Functions\n",
        "def clahe_preprocess(img):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    return clahe.apply(img)\n",
        "\n",
        "def load_images_from_zip(zip_file_path, image_ext=\".tif\"):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_file_list = zip_ref.namelist()\n",
        "        image_files = sorted([f for f in zip_file_list if f.endswith(image_ext) and \"mask\" not in f])\n",
        "        mask_files = sorted([f for f in zip_file_list if f.endswith(image_ext) and \"mask\" in f])\n",
        "\n",
        "        for image_file, mask_file in tqdm(zip(image_files, mask_files), total=len(image_files), desc=\"Loading Images and Masks\"):\n",
        "            # Read and preprocess image\n",
        "            with zip_ref.open(image_file) as img_file:\n",
        "                img_data = img_file.read()\n",
        "                img_array = np.frombuffer(img_data, np.uint8)\n",
        "                img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                if img is not None:\n",
        "                    preprocessed_img = clahe_preprocess(img)\n",
        "                    images.append(preprocessed_img)\n",
        "                else:\n",
        "                    print(f\"Warning: Could not decode image file {image_file}, skipping.\")\n",
        "\n",
        "            # Read mask\n",
        "            with zip_ref.open(mask_file) as mask_file:\n",
        "                mask_data = mask_file.read()\n",
        "                mask_array = np.frombuffer(mask_data, np.uint8)\n",
        "                mask = cv2.imdecode(mask_array, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                if mask is not None:\n",
        "                    masks.append(mask)\n",
        "                else:\n",
        "                    print(f\"Warning: Could not decode mask file {mask_file}, skipping.\")\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "# Model Architectures\n",
        "def unet_pp(input_size=(256, 256, 1)):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # Downsampling path\n",
        "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Upsampling path\n",
        "    up2 = layers.UpSampling2D(size=(4, 4))(pool2)  # Upsample back to 256x256\n",
        "    up2_conv = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up2)\n",
        "\n",
        "    # Concatenate the upsampled feature map with the corresponding downsampled feature map\n",
        "    merge2 = layers.Concatenate(axis=3)([conv1, up2_conv])\n",
        "\n",
        "    conv_final = layers.Conv2D(1, (1, 1), activation='sigmoid')(merge2)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv_final)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
        "\n",
        "    return model\n",
        "\n",
        "def attention_gate(x, g, inter_channel):\n",
        "    theta_x = layers.Conv2D(inter_channel, (1, 1), use_bias=False)(x)\n",
        "    phi_g = layers.Conv2D(inter_channel, (1, 1), use_bias=False)(g)\n",
        "\n",
        "    f = layers.Activation('relu')(layers.add([theta_x, phi_g]))\n",
        "    psi_f = layers.Conv2D(1, (1, 1), use_bias=False)(f)\n",
        "\n",
        "    rate = layers.Activation('sigmoid')(psi_f)\n",
        "    att_x = layers.multiply([x, rate])\n",
        "\n",
        "    return att_x\n",
        "\n",
        "def attention_unet(input_size=(256, 256, 1)):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "\n",
        "    # Decoder\n",
        "    up2 = layers.UpSampling2D(size=(2, 2))(conv3)\n",
        "    att2 = attention_gate(conv2, up2, 128)\n",
        "    up2 = layers.concatenate([up2, att2])\n",
        "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same')(up2)\n",
        "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
        "\n",
        "    up1 = layers.UpSampling2D(size=(2, 2))(conv4)\n",
        "    att1 = attention_gate(conv1, up1, 64)\n",
        "    up1 = layers.concatenate([up1, att1])\n",
        "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same')(up1)\n",
        "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv5)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Model Training and Evaluation\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1e-7) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1e-7)\n",
        "\n",
        "def train_and_evaluate(model, X_train, Y_train, X_test, Y_test, model_name, epochs=50, batch_size=32):\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        f\"{model_name}_best.keras\",\n",
        "        monitor='val_mean_io_u',\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "    early_stopping = EarlyStopping(monitor='val_mean_io_u', mode='max', patience=10, verbose=1)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, Y_train,\n",
        "        validation_data=(X_test, Y_test),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[checkpoint, early_stopping]\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.load_weights(f\"{model_name}_best.keras\")\n",
        "    test_loss, test_iou = model.evaluate(X_test, Y_test)\n",
        "    test_dice = dice_coefficient(Y_test, model.predict(X_test))\n",
        "\n",
        "    print(f\"{model_name} Test IoU: {test_iou}\")\n",
        "    print(f\"{model_name} Test Dice Score: {test_dice}\")\n",
        "\n",
        "    return history, test_iou, test_dice\n",
        "\n",
        "# Main execution\n",
        "if _name_ == \"_main_\":\n",
        "    # Load and preprocess data\n",
        "    zip_file_path = \"/content/Data (1).zip\"\n",
        "    X_images, Y_masks = load_images_from_zip(zip_file_path)\n",
        "\n",
        "    # Data normalization and splitting\n",
        "    X_images = X_images / 255.0\n",
        "    Y_masks = Y_masks / 255.0\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X_images, Y_masks, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"Training data: {len(X_train)} images, Testing data: {len(X_test)} images\")\n",
        "\n",
        "    # Train and evaluate U-Net++\n",
        "    unetpp_model = unet_pp()\n",
        "    unetpp_history, unetpp_iou, unetpp_dice = train_and_evaluate(unetpp_model, X_train, Y_train, X_test, Y_test, \"unetpp\")\n",
        "\n",
        "    # Train and evaluate Attention U-Net\n",
        "    attention_unet_model = attention_unet()\n",
        "    attention_unet_history, attention_unet_iou, attention_unet_dice = train_and_evaluate(attention_unet_model, X_train, Y_train, X_test, Y_test, \"attention_unet\")\n",
        "\n",
        "    # Compare model performances\n",
        "    print(\"\\nModel Comparison:\")\n",
        "    print(f\"U-Net++ IoU: {unetpp_iou}, Dice Score: {unetpp_dice}\")\n",
        "    print(f\"Attention U-Net IoU: {attention_unet_iou}, Dice Score: {attention_unet_dice}\")\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(121)\n",
        "    plt.plot(unetpp_history.history['mean_io_u'], label='U-Net++ Train IoU')\n",
        "    plt.plot(unetpp_history.history['val_mean_io_u'], label='U-Net++ Val IoU')\n",
        "    plt.plot(attention_unet_history.history['mean_io_u'], label='Attention U-Net Train IoU')\n",
        "    plt.plot(attention_unet_history.history['val_mean_io_u'], label='Attention U-Net Val IoU')\n",
        "    plt.title('Model IoU')\n",
        "    plt.ylabel('IoU')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plt.plot(unetpp_history.history['loss'], label='U-Net++ Train Loss')\n",
        "    plt.plot(unetpp_history.history['val_loss'], label='U-Net++ Val Loss')\n",
        "    plt.plot(attention_unet_history.history['loss'], label='Attention U-Net Train Loss')\n",
        "    plt.plot(attention_unet_history.history['val_loss'], label='Attention U-Net Val Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    }
  ]
}
